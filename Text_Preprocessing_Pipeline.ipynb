{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb491e2a-0016-415c-91e8-f03808a679f9",
   "metadata": {},
   "source": [
    "## Text Preprocessing Pipeline Code.\n",
    "### This notebook contains the code for complete text preprocessing.\n",
    "#### Steps followed in preprocessing:\n",
    "    1. Decoding or removing encoding\n",
    "    2. Lower casing\n",
    "    3. Convert digits to words\n",
    "    4. Remove punctuations and other special characters\n",
    "    5. Spelling corrections\n",
    "    6. Remove stop words\n",
    "    7. Stemming\n",
    "    8. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9b9328-35cb-4b69-a1b0-cd93530b8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "# !pip install nltk num2words autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac446019-3681-4ab4-8654-fd9882e500c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rmali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rmali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rmali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from num2words import num2words\n",
    "import nltk \n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09bd64b-0919-456c-961c-ace2febdb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_encoding(text):\n",
    "    \"\"\"\n",
    "    Removes encoding tags from the input text and returns a clean string.\n",
    "\n",
    "    This function identifies and removes any text enclosed in angle brackets,\n",
    "    such as <SUBJECT LINE>, <END>, <BODY TEXT>, etc. It replaces these tags\n",
    "    with a single space to maintain proper separation of content. The resulting\n",
    "    text is cleaned up by removing any excess whitespace and ensuring it remains \n",
    "    in a single line.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string containing encoded tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text with encoding tags removed and content in a single line.\n",
    "    \"\"\"\n",
    "    # Replace any tag enclosed in angle brackets with a single space\n",
    "    cleaned_text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    \n",
    "    # Remove any excess whitespace\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def digits_to_words(match):\n",
    "    \"\"\"\n",
    "    Converts numeric digits in a string to their corresponding words. \n",
    "    Handles both ordinal and cardinal numbers.\n",
    "\n",
    "    Args:\n",
    "        match (re.Match): A regular expression match object containing the numeric string.\n",
    "\n",
    "    Returns:\n",
    "        str: The number converted to words, in either ordinal or cardinal form.\n",
    "    \"\"\"\n",
    "    suffixes = ['st', 'nd', 'rd', 'th']\n",
    "    string = match[0].lower()\n",
    "    if string[-2:] in suffixes:\n",
    "        type = 'ordinal'\n",
    "        string = string[:-2]\n",
    "    else:\n",
    "        type = 'cardinal'\n",
    "\n",
    "    return num2words(string, to=type)\n",
    "\n",
    "\n",
    "def spelling_correction(text):\n",
    "    \"\"\"\n",
    "    Corrects the spelling of words in the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text that may contain misspelled words.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with corrected spelling.\n",
    "    \"\"\"\n",
    "    corrector = Speller()\n",
    "    spells = [corrector(word) for word in text.split()]\n",
    "    return \" \".join(spells)\n",
    "\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Removes common English stop words from the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text that may contain stop words.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with stop words removed.\n",
    "    \"\"\"\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word not in stopwords_set])\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    \"\"\"\n",
    "    Applies stemming to the words in the input text, reducing them to their base or root form.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text that may contain words to be stemmed.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with words stemmed.\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def lemmatizing(text):\n",
    "    \"\"\"\n",
    "    Applies lemmatization to the words in the input text, converting them to their base or dictionary form.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text that may contain words to be lemmatized.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with words lemmatized.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af800467-0115-4853-9ee5-3760bc102f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(input_text):\n",
    "    \"\"\"\n",
    "    Applies a series of text preprocessing steps to the input text, including encoding removal, \n",
    "    case normalization, digit-to-word conversion, punctuation removal, spelling correction, \n",
    "    stop word removal, stemming, and lemmatization.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The raw text that needs to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        str: The fully preprocessed text.\n",
    "    \"\"\"\n",
    "    output = input_text\n",
    "\n",
    "    # Step 1: Decoding or removing encoding\n",
    "    output = remove_encoding(output)\n",
    "    print(\"\\nAfter decoding or removing encoding:\\n    \", output)\n",
    "\n",
    "    # Step 2: Lower casing\n",
    "    output = output.lower()\n",
    "    print(\"\\nAfter lower casing:\\n    \", output)\n",
    "\n",
    "    # Step 3: Convert digits to words\n",
    "    # The following regex syntax looks for matches of consecutive digits followed by an optional ordinal suffix\n",
    "    output = re.sub(r'\\d+(st)?(nd)?(rd)?(th)?', digits_to_words, output, flags=re.IGNORECASE)\n",
    "    print(\"\\nAfter converting digits to words\\n    \", output)\n",
    "\n",
    "    # Step 4: Remove punctuations and other special characters\n",
    "    output = re.sub('[^ A-Za-z0-9]+', '', output)\n",
    "    print(\"\\nAfter removing punctuations and other special characters\\n    \", output)\n",
    "\n",
    "    # Step 5: Spelling corrections\n",
    "    output = spelling_correction(output)\n",
    "    print(\"\\nAfter spelling corrections:\\n    \", output)\n",
    "\n",
    "    # Step 6: Remove stop words\n",
    "    output = remove_stop_words(output)\n",
    "    print(\"\\nAfter removing stop words:\\n    \", output)\n",
    "\n",
    "    # Step 7: Stemming\n",
    "    output = stemming(output)\n",
    "    print(\"\\nAfter stemming:\\n    \", output)\n",
    "\n",
    "    # Step 8: Lemmatizing\n",
    "    output = lemmatizing(output)\n",
    "    print(\"\\nAfter lemmatization:\\n    \", output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664d7e15-f909-4754-85d8-553a8a2e3699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Input Text:\n",
      " \n",
      "    \"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\n",
      "1st one is pairoll, 2nd is healtcare!<END>\"\n",
      "    \n",
      "\n",
      "\n",
      "Preprocessing............\n",
      "\n",
      "After decoding or removing encoding:\n",
      "     \" Employees details Attached are 2 files, 1st one is pairoll, 2nd is healtcare! \"\n",
      "\n",
      "After lower casing:\n",
      "     \" employees details attached are 2 files, 1st one is pairoll, 2nd is healtcare! \"\n",
      "\n",
      "After converting digits to words\n",
      "     \" employees details attached are two files, first one is pairoll, second is healtcare! \"\n",
      "\n",
      "After removing punctuations and other special characters\n",
      "      employees details attached are two files first one is pairoll second is healtcare \n",
      "\n",
      "After spelling corrections:\n",
      "     employees details attached are two files first one is payroll second is healthcare\n",
      "\n",
      "After removing stop words:\n",
      "     employees details attached two files first one payroll second healthcare\n",
      "\n",
      "After stemming:\n",
      "     employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "After lemmatization:\n",
      "     employe detail attach two file first one payrol second healthcar\n",
      "\n",
      "................................\n",
      "This is the preprocessed text:\n",
      "  employe detail attach two file first one payrol second healthcar\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "    \"<SUBJECT LINE> Employees details<END><BODY TEXT>Attached are 2 files,\\n1st one is pairoll, 2nd is healtcare!<END>\"\n",
    "    \"\"\"\n",
    "print(f\"Raw Input Text:\\n {raw_text}\")\n",
    "print(\"\\n\\nPreprocessing............\")\n",
    "preprocessed_text = text_preprocessing(raw_text)\n",
    "print(f\"\\n................................\\nThis is the preprocessed text:\\n  {preprocessed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fbe98-2454-4ece-b3d0-e44e9ffd3c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
